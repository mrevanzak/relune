# Rêlune Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Status:** Task 7 Complete (WhatsApp Import) | Next: Task 8 (In-App Recording Upload)

**Goal:** Build the MVP of Rêlune, a private voice recording app with transcription and search, covering backend foundation and mobile core flow.

**Architecture:** Monorepo with Expo/RN mobile app and Elysia/Bun backend. Supabase for DB/Storage/Auth. Vercel AI SDK for transcription.

**Tech Stack:** React Native, Expo 54, Elysia, Drizzle, Supabase, Vercel AI SDK, TanStack Query.

---

## Phase 1: Foundation (Backend & Schema)

### Task 1: Database Schema & Enums ✅ DONE

**Files:**
- Modify: `packages/db/src/schema/index.ts`
- Modify: `packages/db/drizzle.config.ts` (if needed)

**Step 1: Define Enums & Users Table**
Add `languageEnum`, `importSourceEnum`, and `users` table to `packages/db/src/schema/index.ts`.

```typescript
import { pgTable, pgEnum, uuid, text, timestamp } from 'drizzle-orm/pg-core';

export const languageEnum = pgEnum('language', ['en', 'fr', 'mixed']);
export const importSourceEnum = pgEnum('import_source', ['app', 'whatsapp']);

export const users = pgTable('users', {
  id: uuid('id').primaryKey(), // Matches Supabase Auth ID
  email: text('email').notNull().unique(),
  displayName: text('display_name'),
  createdAt: timestamp('created_at').defaultNow().notNull(),
});
```

**Step 2: Generate Migration**
Run: `bun run db:generate` (ensure script exists in `packages/db/package.json`)
Expected: Migration file created.

**Step 3: Define Recordings Table**
Add `recordings` table with relations to `users`.

```typescript
import { integer } from 'drizzle-orm/pg-core';

export const recordings = pgTable('recordings', {
  id: uuid('id').primaryKey().defaultRandom(),
  userId: uuid('user_id').notNull().references(() => users.id),
  audioUrl: text('audio_url').notNull(),
  durationSeconds: integer('duration_seconds'),
  fileSizeBytes: integer('file_size_bytes'),
  transcript: text('transcript'),
  language: languageEnum('language'),
  recordedAt: timestamp('recorded_at').notNull(),
  importSource: importSourceEnum('import_source').default('app').notNull(),
  originalFilename: text('original_filename'),
  createdAt: timestamp('created_at').defaultNow().notNull(),
  updatedAt: timestamp('updated_at').defaultNow().notNull(),
});
```

**Step 4: Define Keywords & Junction Table**
Add `keywords` and `recordingKeywords` tables.

```typescript
import { boolean, primaryKey } from 'drizzle-orm/pg-core';

export const keywords = pgTable('keywords', {
  id: uuid('id').primaryKey().defaultRandom(),
  name: text('name').notNull().unique(),
  createdAt: timestamp('created_at').defaultNow().notNull(),
});

export const recordingKeywords = pgTable('recording_keywords', {
  recordingId: uuid('recording_id').notNull().references(() => recordings.id, { onDelete: 'cascade' }),
  keywordId: uuid('keyword_id').notNull().references(() => keywords.id, { onDelete: 'cascade' }),
  isAutoGenerated: boolean('is_auto_generated').default(true).notNull(),
}, (t) => ({
  pk: primaryKey({ columns: [t.recordingId, t.keywordId] }),
}));
```

**Step 5: Export Types**
Add inferred types at the bottom of `schema/index.ts`.

```typescript
export type User = typeof users.$inferSelect;
export type Recording = typeof recordings.$inferSelect;
// ... etc
```

**Step 6: Commit**
```bash
git add packages/db/src/schema/index.ts
git commit -m "feat(db): define initial schema for users, recordings, keywords"
```

### Task 2: Backend Auth Middleware ✅ DONE

**Files:**
- Create: `apps/server/src/middleware/auth.ts`
- Modify: `apps/server/src/index.ts`

**Step 1: Install Dependencies**
Run: `bun add @supabase/supabase-js` in `apps/server`

**Step 2: Create Auth Middleware**
Implement middleware that verifies Supabase JWT and checks email whitelist.

```typescript
import { Elysia } from 'elysia';
import { createClient } from '@supabase/supabase-js';

const supabase = createClient(process.env.SUPABASE_URL!, process.env.SUPABASE_SERVICE_ROLE_KEY!);
const WHITELIST = (process.env.ALLOWED_EMAILS || '').split(',');

export const auth = new Elysia({ name: 'auth' })
  .derive(async ({ request, set }) => {
    const authHeader = request.headers.get('Authorization');
    if (!authHeader) {
      set.status = 401;
      throw new Error('No authorization header');
    }

    const token = authHeader.replace('Bearer ', '');
    const { data: { user }, error } = await supabase.auth.getUser(token);

    if (error || !user) {
      set.status = 401;
      throw new Error('Invalid token');
    }

    if (!WHITELIST.includes(user.email!)) {
      set.status = 403;
      throw new Error('Email not authorized');
    }

    return { user };
  });
```

**Step 3: Register Middleware**
Update `apps/server/src/index.ts` to use auth middleware.

**Step 4: Commit**
```bash
git add apps/server/src/middleware/auth.ts apps/server/src/index.ts
git commit -m "feat(server): add auth middleware with whitelist"
```

### Task 3: Backend Recordings API (Basic CRUD) ✅ DONE

**Files:**
- Create: `apps/server/src/routes/recordings.ts`
- Modify: `apps/server/src/index.ts`

**Step 1: List Endpoint**
Implement `GET /recordings` with pagination support using Drizzle.

**Step 2: Get Endpoint**
Implement `GET /recordings/:id`.

**Step 3: Register Routes**
Add routes to `apps/server/src/index.ts`.

**Step 4: Commit**
```bash
git add apps/server/src/routes/recordings.ts
git commit -m "feat(server): add basic recordings CRUD"
```

## Phase 2: Mobile Foundation

### Task 4: Mobile Auth Setup ✅ DONE

**Files:**
- Create: `apps/native/lib/supabase.ts`
- Create: `apps/native/components/AuthGate.tsx`
- Modify: `apps/native/app/_layout.tsx`

**Step 1: Install Dependencies**
Run in `apps/native`:
`npx expo install expo-secure-store @supabase/supabase-js expo-local-authentication`

**Step 2: Initialize Supabase Client**
Create `lib/supabase.ts` using SecureStore for token persistence.

**Step 3: Create AuthGate Component**
Implement `AuthGate` that checks authentication state and redirects to login if needed.

**Step 4: Commit**
```bash
git add apps/native/lib/supabase.ts apps/native/components/AuthGate.tsx
git commit -m "feat(native): setup supabase auth and auth gate"
```

### Task 5: Mobile Biometric Lock ✅ DONE

**Files:**
- Create: `apps/native/components/BiometricLock.tsx`
- Modify: `apps/native/app/_layout.tsx`

**Step 1: Implement Biometric Logic**
Use `expo-local-authentication` to prompt FaceID on app resume.

**Step 2: Integrate into Layout**
Wrap the root layout with `BiometricLock`.

**Step 3: Commit**
```bash
git add apps/native/components/BiometricLock.tsx
git commit -m "feat(native): add biometric lock screen"
```

## Phase 3: Core Recording Flow

### Task 6: Audio Recording Implementation ✅ DONE

**Files:**
- Modify: `apps/native/app/index.tsx` (or new recording screen)
- Create: `apps/native/hooks/useAudioRecorder.ts`

**Step 1: Install Audio Lib**
Run: `npx expo install expo-audio`

**Step 2: Create Recorder Hook**
Implement `useAudioRecorder` to handle `start`, `stop`, and duration tracking.

**Step 3: Build UI**
Create a simple recording UI with visual feedback.

**Step 4: Commit**
```bash
git add apps/native/hooks/useAudioRecorder.ts
git commit -m "feat(native): implement audio recording logic"
```

### Task 7: WhatsApp Import Pipeline

**Design:** See `docs/plans/2025-12-25-whatsapp-import-design.md`

**Files:**
- Modify: `packages/db/src/schema/index.ts` (add `notes` field)
- Create: `apps/server/src/modules/import/index.ts` (controller)
- Create: `apps/server/src/modules/import/service.ts` (parser, storage, user resolution)
- Modify: `apps/server/src/modules/recordings/service.ts` (transcription job)
- Modify: `apps/server/src/index.ts` (register routes)

**Step 1: Schema Update**
Add `notes` field to `recordings` table for storing associated text messages.

```typescript
notes: text('notes'),  // Optional text context from WhatsApp
```

**Step 2: WhatsApp Parser Service**
Create service to:
- Extract zip file contents
- Parse `_chat.txt` format: `[MM/DD/YY, HH:MM:SS] Sender: <attached: filename.opus>`
- Map audio files to metadata (timestamp, sender, optional notes)

**Step 3: User Resolution**
Query `users` table by `display_name`. If not found, create user with:
- `display_name`: sender name from chat
- `email`: placeholder like `{slugified-name}@import.local`

**Step 4: Import Endpoint**
Implement `POST /import/whatsapp`:
- Accept `multipart/form-data` with zip file
- For each audio: check duplicate, resolve user, upload to storage, insert record
- Return `{ imported, skipped, failed, recordings }`

**Step 5: Transcription Job**
Implement `POST /recordings/process-pending`:
- Query `WHERE transcript IS NULL LIMIT ?`
- Fetch audio, call AI SDK transcribe, update record
- Generate keywords with GPT-4o-mini
- Return `{ processed, remaining, errors }`

**Step 6: Commit**
```bash
git add packages/db/src/schema/index.ts apps/server/src/modules/import
git commit -m "feat(server): implement WhatsApp import and transcription pipeline"
```

### Task 8: Upload & Transcription (In-App Recording)

**Files:**
- Modify: `apps/server/src/modules/recordings/index.ts`
- Create: `apps/native/lib/api.ts`

**Step 1: Server Upload Handler**
Implement `POST /recordings` to accept `multipart/form-data`, upload to Supabase Storage, and save DB record with `importSource: 'app'`.

**Step 2: Reuse Transcription Job**
New recordings with `transcript: null` are picked up by the existing `process-pending` job from Task 7.

**Step 3: Client Mutation**
Implement upload mutation in mobile app using `eden` treaty.

**Step 4: Commit**
```bash
git add apps/server/src/modules/recordings
git commit -m "feat(server): implement in-app recording upload"
```
